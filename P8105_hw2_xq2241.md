p8105_hw2_xq2241
================
Xinghao Qiao
2024-09-28

# Question 1

First, we import the dataset in R markdown.

``` r
library(tidyr)
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
library(readr)
library(readxl)
library(stringr)
ny_transit<- read_csv ("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Rows: 1868 Columns: 32

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Then, we can clean our data

``` r
#data should remain these varaibles
cleaned_ny <- ny_transit|> select(Line,`Station Name`,`Station Latitude`,`Station Longitude`,starts_with("Route"),Entry,Vending,`Entrance Type`,ADA)
#convert entry varialbe to logical variable
cleaned_ny <- cleaned_ny |> mutate(Entry=ifelse(Entry == "YES",T,F))
#getting dimension of the cleaned data
summary(cleaned_ny)
```

    ##      Line           Station Name       Station Latitude Station Longitude
    ##  Length:1868        Length:1868        Min.   :40.58    Min.   :-74.03   
    ##  Class :character   Class :character   1st Qu.:40.69    1st Qu.:-73.99   
    ##  Mode  :character   Mode  :character   Median :40.73    Median :-73.96   
    ##                                        Mean   :40.73    Mean   :-73.94   
    ##                                        3rd Qu.:40.77    3rd Qu.:-73.91   
    ##                                        Max.   :40.90    Max.   :-73.76   
    ##                                                                          
    ##     Route1             Route2             Route3             Route4         
    ##  Length:1868        Length:1868        Length:1868        Length:1868       
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##     Route5             Route6             Route7              Route8     
    ##  Length:1868        Length:1868        Length:1868        Min.   :1.000  
    ##  Class :character   Class :character   Class :character   1st Qu.:1.000  
    ##  Mode  :character   Mode  :character   Mode  :character   Median :4.000  
    ##                                                           Mean   :2.979  
    ##                                                           3rd Qu.:5.000  
    ##                                                           Max.   :5.000  
    ##                                                           NA's   :1820   
    ##      Route9         Route10        Route11       Entry        
    ##  Min.   :2.000   Min.   :3      Min.   :7      Mode :logical  
    ##  1st Qu.:2.000   1st Qu.:3      1st Qu.:7      FALSE:115      
    ##  Median :2.000   Median :3      Median :7      TRUE :1753     
    ##  Mean   :2.536   Mean   :3      Mean   :7                     
    ##  3rd Qu.:2.000   3rd Qu.:3      3rd Qu.:7                     
    ##  Max.   :5.000   Max.   :3      Max.   :7                     
    ##  NA's   :1840    NA's   :1845   NA's   :1845                  
    ##    Vending          Entrance Type         ADA         
    ##  Length:1868        Length:1868        Mode :logical  
    ##  Class :character   Class :character   FALSE:1400     
    ##  Mode  :character   Mode  :character   TRUE :468      
    ##                                                       
    ##                                                       
    ##                                                       
    ## 

As an overview of this dataset, this dataset contains information
related to each entrance and exit for each subway station in NYC,
including line, station, name, station latitude / longitude, routes
served, entry, vending, entrance type, and ADA compliance. The new
dataset contains 1868 rows and 19 columns.To clean the dataset, I
retained the revalent variables and converted the entry variable from
character (YES vs NO) to a logical variable.Now, I would use the cleaned
dataset to answer questions.

``` r
#count the number of stations
distinct_station<-cleaned_ny|>distinct(`Station Name`,Line)|>nrow()
distinct_station
```

    ## [1] 465

``` r
#count ADA compliant
ada_c<-cleaned_ny|>filter(ADA == TRUE)|> nrow()
ada_c
```

    ## [1] 468

``` r
#calculate proportion of station entrances / exits without vending allow entrance
no_vd_entry<-cleaned_ny|>filter(Vending == "NO",Entry==T)|> nrow()
no_vd<-cleaned_ny|>filter(Vending == "NO")|>nrow()
prop<-no_vd_entry/no_vd
prop
```

    ## [1] 0.3770492

So, based on our cleaned data, there are 465 distinct stations,468 ADA
compliant stations and proportion of station entrances / exits without
vending allow entrance is 37.7%.

Then, I would reformat data so that route number and route name are
distinct variables.

``` r
r_data<-cleaned_ny|>mutate(across(starts_with("Route"), as.character))|> pivot_longer(cols=starts_with("Route"),names_to="Route.Number",values_to = "Route.Name")|>filter(!is.na(Route.Name))
```

Now, we can answer the question with new dataset.

``` r
#count distinct stations serve the A train
sta_A<-r_data|>filter(Route.Name == "A")|> distinct(`Station Name`,Line)|> nrow()
sta_A
```

    ## [1] 60

``` r
#count ADA compliant of station(serve A)
ada_a<-r_data|>filter(Route.Name == "A", ADA == TRUE)|> distinct(`Station Name`,Line)|>nrow()
ada_a
```

    ## [1] 17

So,after reformating the dataset, there are 60 distinct stations serve
the A train and 17 ADA compliant stations serving the train A.

# Question 2

First, we import the dataset

``` r
mr_trash<-read_excel("202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
pro_trash<-read_excel("202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel")
gwy<-read_excel("202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel")
```

Then, we can clean these three datasets and combine them together.

``` r
#mr. trash wheel
cleaned_mr_trash<- mr_trash|> mutate(Wheel = "mr_trash")|>
  filter(!is.na(Dumpster))|>
  mutate(`Sports Balls`=as.integer(round(`Sports Balls`,0)))
#professor trash wheel
cleaned_pro_trash<- pro_trash|> mutate(Wheel = "pro_trash")|>
  filter(!is.na(Dumpster))
#gwynnda trash wheel
cleaned_gwy_trash<- gwy|> mutate(Wheel = "gwy_trash")|>
  filter(!is.na(Dumpster))
#combine
cleaned_mr_trash <- cleaned_mr_trash |>
  mutate(Year = as.numeric(Year))

cleaned_pro_trash <- cleaned_pro_trash |>
  mutate(Year = as.numeric(Year))

cleaned_gwy_trash <- cleaned_gwy_trash |>
  mutate(Year = as.numeric(Year))

combined_data<-bind_rows(cleaned_mr_trash,cleaned_pro_trash,cleaned_gwy_trash)
```

Now,we can use combined data to answer questions.

``` r
#number of observations
num_observations <- nrow(combined_data)
num_observations
```

    ## [1] 845

``` r
#the total weight of trash collected by Professor Trash Wheel
pro_weight <- combined_data |>
  filter(Wheel == "pro_trash") |>
  summarise(Total_Weight = sum(`Weight (tons)`, na.rm =TRUE))|>pull(Total_Weight)
pro_weight
```

    ## [1] 216.26

``` r
#the total number of cigarette butts collected by Gwynnda in June of 2022
total_cig_gwy <- combined_data |>
  filter(Wheel == "gwy_trash", Month == "June", Year == 2022) |>
  summarise(Total_Cigarette = sum(`Cigarette Butts`, na.rm = TRUE)) |>
  pull(Total_Cigarette)
total_cig_gwy
```

    ## [1] 18120

So,there are 845 observations in the combined dataset, the total weight
of trash collected by Professor Trash Wheel is 216.26 tons and the total
number of cigarette butts collected by Gwynnda in June of 2022 is 18120.

# Question 3

``` r
#import the datasets
bakers <- read_csv("gbb_datasets/bakers.csv")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes <- read_csv("gbb_datasets/bakes.csv")
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results <- read_csv("gbb_datasets/results.csv",skip = 2)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers <- read_csv("gbb_datasets/viewers.csv")
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Check for completeness and missing data
bakers <- bakers |>
  mutate(Baker_First_Name = sub(" .*", "", `Baker Name`))
bakes <- bakes |>
  mutate(Baker = gsub('\"', '', Baker)) 

bb<-anti_join(bakes, bakers, by = c("Baker" = "Baker_First_Name"))
bb
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: Series <dbl>, Episode <dbl>, Baker <chr>,
    ## #   Signature Bake <chr>, Show Stopper <chr>

``` r
cc<-anti_join(results, bakers, by = c("baker" = "Baker_First_Name"))
cc
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

By comparing these three tables (‘bakes’,‘bakers’,‘results’), I can make
sure that “Jo” in bakes, Jo Wheatley in bakers and Joanne in results are
the same person. So, I would rename this person as Jo.

``` r
results <- results |>
  mutate(baker = ifelse(baker == "Joanne", "Jo", baker))
#sceond check
cc<-anti_join(results, bakers, by = c("baker" = "Baker_First_Name"))
cc
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

``` r
print(bakers)
```

    ## # A tibble: 120 × 6
    ##    `Baker Name`  Series `Baker Age` `Baker Occupation` Hometown Baker_First_Name
    ##    <chr>          <dbl>       <dbl> <chr>              <chr>    <chr>           
    ##  1 Ali Imdad          4          25 Charity worker     Saltley… Ali             
    ##  2 Alice Fevron…     10          28 Geography teacher  Essex    Alice           
    ##  3 Alvin Magall…      6          37 Nurse              Brackne… Alvin           
    ##  4 Amelia LeBru…     10          24 Fashion designer   Halifax  Amelia          
    ##  5 Andrew Smyth       7          25 Aerospace engineer Derby /… Andrew          
    ##  6 Annetha Mills      1          30 Midwife            Essex    Annetha         
    ##  7 Antony Amour…      9          30 Banker             London   Antony          
    ##  8 Beca Lyne-Pi…      4          31 Military Wives' C… Aldersh… Beca            
    ##  9 Ben Frazer         2          31 Graphic Designer   Northam… Ben             
    ## 10 Benjamina Eb…      7          23 Teaching assistant South L… Benjamina       
    ## # ℹ 110 more rows

So, now we can merge the dataset

``` r
merged_data <- bakes |>
  left_join(bakers, by = c("Baker" = "Baker_First_Name"),relationship = "many-to-many")|>
  left_join(results, by = c("Baker"="baker"))
```

    ## Warning in left_join(left_join(bakes, bakers, by = c(Baker = "Baker_First_Name"), : Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 1 of `x` matches multiple rows in `y`.
    ## ℹ Row 2 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
final_data <- merged_data |>
  select(`Baker Name`, `Baker Age`, `Baker Occupation`, Hometown, Episode,Series.x, `Signature Bake`, `Show Stopper`, result, everything())

write_csv(final_data, "final_dataset.csv")
```

Now, we creat the star baker and winner table

``` r
star_baker_winner_table <- results |>
  filter(series >= 5 & series <= 10) |>   # episode in Seasons 5 through 10
  filter(result == "STAR BAKER" | result == "WINNER") |>  
  select(series, episode, baker, result) |>  
  arrange(series, episode)  

print(star_baker_winner_table)
```

    ## # A tibble: 60 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       2 Richard STAR BAKER
    ##  3      5       3 Luis    STAR BAKER
    ##  4      5       4 Richard STAR BAKER
    ##  5      5       5 Kate    STAR BAKER
    ##  6      5       6 Chetna  STAR BAKER
    ##  7      5       7 Richard STAR BAKER
    ##  8      5       8 Richard STAR BAKER
    ##  9      5       9 Richard STAR BAKER
    ## 10      5      10 Nancy   WINNER    
    ## # ℹ 50 more rows

Now, I would like to use frequency table to analyze if there were any
predictable overall winners

``` r
baker_frequency <- star_baker_winner_table |>
  group_by(baker) |>
  summarise(frequency = n()) |> 
  arrange(desc(frequency))  

print(baker_frequency)
```

    ## # A tibble: 32 × 2
    ##    baker   frequency
    ##    <chr>       <int>
    ##  1 Richard         5
    ##  2 Candice         4
    ##  3 Nadiya          4
    ##  4 Steph           4
    ##  5 Ian             3
    ##  6 Rahul           3
    ##  7 Sophie          3
    ##  8 Steven          3
    ##  9 Alice           2
    ## 10 Andrew          2
    ## # ℹ 22 more rows

So, from the frequency table, Richard could be a predictable overall
winner.

Now,we use ‘viewers’ dataset.

``` r
viewers <- read_csv("gbb_datasets/viewers.csv")
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, 10)
```

    ## # A tibble: 10 × 11
    ##    Episode `Series 1` `Series 2` `Series 3` `Series 4` `Series 5` `Series 6`
    ##      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>
    ##  1       1       2.24       3.1        3.85       6.6        8.51       11.6
    ##  2       2       3          3.53       4.6        6.65       8.79       11.6
    ##  3       3       3          3.82       4.53       7.17       9.28       12.0
    ##  4       4       2.6        3.6        4.71       6.82      10.2        12.4
    ##  5       5       3.03       3.83       4.61       6.95       9.95       12.4
    ##  6       6       2.75       4.25       4.82       7.32      10.1        12  
    ##  7       7      NA          4.42       5.1        7.76      10.3        12.4
    ##  8       8      NA          5.06       5.35       7.41       9.02       11.1
    ##  9       9      NA         NA          5.7        7.41      10.7        12.6
    ## 10      10      NA         NA          6.74       9.45      13.5        15.0
    ## # ℹ 4 more variables: `Series 7` <dbl>, `Series 8` <dbl>, `Series 9` <dbl>,
    ## #   `Series 10` <dbl>

``` r
#reshape data
viewers_tidy <- viewers |>
  pivot_longer(cols = starts_with("Series"), names_to = "Season", values_to = "Viewership")
```

Now, we can calculate.

``` r
#average viewership in Season 1
avg_season1 <- viewers_tidy |>
  filter(Season == "Series 1") |>
  summarise(avg_viewers = mean(Viewership, na.rm = TRUE))

# average viewership in Season 5
avg_season5 <- viewers_tidy |>
  filter(Season == "Series 5") |>
  summarise(avg_viewers = mean(Viewership, na.rm = TRUE))

avg_season1
```

    ## # A tibble: 1 × 1
    ##   avg_viewers
    ##         <dbl>
    ## 1        2.77

``` r
avg_season5
```

    ## # A tibble: 1 × 1
    ##   avg_viewers
    ##         <dbl>
    ## 1        10.0

From the output, we have the average viewership in Season 1 is 2.77 and
the average viewership in Season 5 is 10.0393.
